{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177feef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, BatchNormalization, MaxPool2D\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed()\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing custom libraries\n",
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "from graphic_utils.symbols import draw_symbols\n",
    "from graphic_utils.confusion_matrix import plot_confusion_matrix\n",
    "\n",
    "# adding support of zip files\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa9e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "dataset = pd.read_csv(\"../data/train.csv.zip\", compression='zip')\n",
    "\n",
    "#Load the test data for the competition submission\n",
    "competition_dataset = pd.read_csv(\"../data/test.csv.zip\", compression='zip')\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A label is the thing we're predicting\n",
    "label = dataset[\"label\"]\n",
    "\n",
    "# A feature is an input variable, in this case a 28 by 28 pixels image\n",
    "# Drop 'label' column\n",
    "feature = dataset.drop(labels = [\"label\"], axis = 1)\n",
    "\n",
    "# let's check we have a good distribution of the handwritten digits\n",
    "g = sns.countplot(x=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# free some space\n",
    "del dataset \n",
    "\n",
    "print(\"Cleaned up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c487165",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_symbols(feature, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aafa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "label = to_categorical(label, num_classes = 10)\n",
    "\n",
    "# Normalize between 0 and 1 the data (The pixel-value is an integer between 0 and 255)\n",
    "feature = feature / 255.0\n",
    "competition_dataset = competition_dataset / 255.0\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation set\n",
    "# Keep 10% for the validation and 90% for the training\n",
    "# Stratify is argument to keep trainingset evenly balanced ofver the labels (eg validation set not only the digit 5)\n",
    "\n",
    "feature_train, feature_val, label_train, label_val = train_test_split(feature, label, test_size = 0.1, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c601a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First model is a dense neural network model with 5 layers\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(200, activation = \"relu\", input_shape = (784,)))\n",
    "model_1.add(Dense(100, activation = \"relu\"))\n",
    "model_1.add(Dense(60, activation = \"relu\"))\n",
    "model_1.add(Dense(30, activation = \"relu\"))\n",
    "model_1.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "# Define the optimizer and compile the model\n",
    "optimizer = optimizers.SGD(lr=0.03, clipnorm=5.)\n",
    "model_1.compile(optimizer= optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "print (model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this model you should be able to achieve around 95.5% accuracy\n",
    "\n",
    "history = model_1.fit(feature_train, label_train, batch_size = 100, epochs = 8, \n",
    "          validation_data = (feature_val, label_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0208f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60959f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = model_1.predict(feature_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(label_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bec77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model_1.predict(competition_dataset)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
